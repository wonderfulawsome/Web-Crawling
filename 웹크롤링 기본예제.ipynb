{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\82106\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\82106\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024년 03월 16일 05시 37분 입니다.\n",
      "\n",
      "       ※ Python Webcrawling Project 1 ※ \n",
      " \n",
      "   환영합니다, 2024년 03월 16일 05시 37분 입니다.\n",
      "      오늘의 주요 정보를 요약해 드리겠습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "nowDate = now.strftime('%Y년 %m월 %d일 %H시 %M분 입니다.')\n",
    "print(nowDate)\n",
    "\n",
    "print(\"\\n       ※ Python Webcrawling Project 1 ※ \\n \")\n",
    "print('   환영합니다, ' + nowDate)\n",
    "print('      오늘의 주요 정보를 요약해 드리겠습니다.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오늘의 날씨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ○>> #오늘의 #날씨 #요약 \n",
      "\n",
      "--> 서울 날씨 :  0.5° 높아요  °  어제보다 0.5° 높아요  맑음 \n",
      "--> 대구 날씨 :  2.7° 높아요  ℃ 어제보다 2.7° 높아요  맑음 \n",
      "--> 부산 날씨 :  0.8° 높아요  ℃ 어제보다 0.8° 높아요  맑음 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "# 오늘의 날씨\n",
    "print('  ○>> #오늘의 #날씨 #요약 \\n')\n",
    "webpage = urllib.request.urlopen('https://search.naver.com/search.naver?sm=top_hty&fbm=0&ie=utf8&query=%EC%84%9C%EC%9A%B8%EB%82%A0%EC%94%A8')\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "temps = soup.find('span',\"temperature up\")\n",
    "cast = soup.find('p',\"summary\")\n",
    "print('--> 서울 날씨 : ' , temps.get_text() , '° ' , cast.get_text())\n",
    "\n",
    "webpage = urllib.request.urlopen('https://search.naver.com/search.naver?sm=top_hty&fbm=0&ie=utf8&query=%EB%8C%80%EA%B5%AC+%EB%82%A0%EC%94%A8')\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "temps = soup.find('span',\"temperature up\")\n",
    "cast = soup.find('p',\"summary\")\n",
    "print('--> 대구 날씨 : ' , temps.get_text() , '℃' , cast.get_text())\n",
    "\n",
    "webpage = urllib.request.urlopen('https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EB%B6%80%EC%82%B0+%EB%82%A0%EC%94%A8&oquery=%EB%8C%80%EA%B5%AC+%EB%82%A0%EC%94%A8&tqi=UrZy%2Bsp0YidssAyki54ssssssKC-251380')\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "temps = soup.find('span',\"temperature up\")\n",
    "cast = soup.find('p',\"summary\")\n",
    "print('--> 부산 날씨 : ' , temps.get_text() , '℃' , cast.get_text())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오늘의 뉴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ○>> #오늘의 #뉴스 #요약 \n",
      "\n",
      "미 민주당 상원 원내대표 “선거 새로 해야”…네타냐후 정권 교체 주장\n",
      "스페이스X '스타십' 3번째 발사 \"궤도비행 성공...대기권 들어오며 분해\"\n",
      "하마스, 구체적 계획 담은 새 휴전안 제시…이스라엘 \"여전히 비현실적\"\n",
      "美 틱톡 금지법 통과에…대만도 '전면 사용금지' 검토 나서\n",
      "인도, 투자하면 전기차 세금 인하…테슬라 구애작전 통했다\n",
      "日 최대 노조 “임금 5.28% 인상”… 33년 만의 최대폭\n",
      "오타니, '한국행 비행기' 앞에서 아내 최초 공개 外[핫클릭]\n",
      "'패스트 패션'에 환경 부담금…프랑스 하원, 법안 가결\n",
      "'30년 집권' 나선 푸틴…대선 득표율 80% 넘길까\n",
      "[지구촌톡톡] \"기후 변화로 바나나 생산에 직격탄…가격 오를 것\" 外\n",
      "덴마크, 유럽 3번째로 '여성 징병제' 도입… 2026년 예정\n",
      "팔 자치정부 새총리 임명 두고 하마스-파타 '신경전'\n",
      "'저항의 축' 하마스-후티 회동… \"이스라엘 라파 침공 대응 논의\"\n",
      "나발니 지지자들 “투표소에 모이자”···대선 중 ‘푸틴 대항’ 시위 추진\n",
      "우크라, 드론 공격으로 흑해 곡물 수출로 열었다\n",
      "\"대낮에 투표소 모여라\"…러시아 대선 중 나발니 지지자 시위\n",
      "인도, '적대' 파키스탄 접경지에 아파치 헬기 부대 창설\n",
      "\"부적절해 보여\" 트럼프 수사 특검, 상사와 불륜 의혹에 사임\n",
      "말 한마디에 6500억원 물어준다…애플 무슨 일\n",
      "신장 근무경력 인사 中 언론담당 임명…'인권 탄압' 비판 반박?\n",
      "바이마르 삼각동맹 [김태훈의 의미 또는 재미]\n",
      "보잉737, 또 비행중 부품 떨어져… 이번엔 공항 착륙 후 알았다\n",
      "\"달에 원전 세우겠다\"...푸틴의 우주 핵무기 야욕\n",
      "팀 쿡 '말 한 마디'에 6500억원 날린 애플…무슨 일?\n",
      "보잉 여객기 또 문제 발생…이번엔 비행 중 패널 뜯겨나가\n",
      "팀 쿡 한마디에 6500억 배상하게 된 애플…뭐라고 했길래?\n",
      "창문 날라가고 바퀴 떨어지더니 이번엔 '패널 실종'… 보잉 여객기 왜 이러나\n",
      "\"미국, 이란과 비밀회담 성과 없자 바로 후티 때렸다\"\n",
      "맥도날드, 세계 곳곳서 ‘전산장애’…“사이버 공격 때문 아냐”\n",
      "\"오타니 보는 눈 있네\"…평범하다던 아내, 학창시절 일화 보니\n",
      "TSMC보다 더 받는 삼성 美보조금…정부당국자 “기대에 상당히 부응”\n",
      "'박빙'으로 돌아선 바이든과 트럼프, 초경합주 잡는 게 관건\n",
      "정부당국자, '삼성전자 美반도체보조금'에 \"기대에 상당히 부응\"\n",
      "푸틴 경고대로 우크라에 미사일 공격…\"최소 20명 사망\"(종합)\n",
      "정인교 \"美정부에 韓기업 충분하고 차별없는 지원 요구\"\n",
      "보잉 여객기 또 사고…이번엔 외장 패널 떨어진 채 비행\n",
      "‘구멍 나고 타이어 빠지고’… 보잉, 이번엔 외부 패널 실종\n",
      "구형 보잉 737-800기, 비행중 외부패널 떨어져나가(종합2보)\n",
      "러시아, 북한 핵 보유국 지위 인정하나?\n",
      "러, 대선 첫날 우크라 오데사항에 미사일…\"최소 20명 사망\"(종합)\n",
      "일본 공장 습격한 장인, '가명' 물려받은 사위 [김종성의 '히, 스토리']\n",
      "애플, '이 말 한마디'에 6천500억 원 빚졌다…어떤 말이었길래\n",
      "비행 중 문짝 떨어지더니…이번엔 '패널 실종'\n",
      "착륙은 잘 했는데…보잉사 항공기 이번엔 '패널 실종'\n",
      "\"첫째도 둘째도 셋째도 전쟁준비\" 김정은, 공수부대 훈련시찰\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print('  ○>> #오늘의 #뉴스 #요약 \\n')\n",
    "\n",
    "# 웹사이트 URL 설정\n",
    "url = 'https://news.naver.com/section/104'\n",
    "\n",
    "# HTTP 요청을 통해 웹페이지 가져오기\n",
    "response = requests.get(url)\n",
    "\n",
    "# 웹페이지의 HTML 파싱\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 'sa_text_title' 클래스를 가진 요소들 찾기\n",
    "titles = soup.select('.sa_text_title')\n",
    "\n",
    "# 찾은 요소들의 텍스트 추출 및 출력\n",
    "for title in titles:\n",
    "    print(title.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음원차트 TOP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음원 차트\n",
      "밤양갱\n",
      "첫 만남은 계획대로 되지 않아\n",
      "나는 아픈 건 딱 질색이니까\n",
      "Love wins all\n",
      "EASY\n",
      "To. X\n",
      "비의 랩소디\n",
      "홀씨\n",
      "Perfect Night\n",
      "헤어지자 말해요\n"
     ]
    }
   ],
   "source": [
    "# 오늘의 음원 TOP10\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 웹사이트 URL 설정\n",
    "url = 'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EC%9D%8C%EC%9B%90%EC%B0%A8%ED%8A%B8'\n",
    "\n",
    "# HTTP 요청을 통해 웹페이지 가져오기\n",
    "response = requests.get(url)\n",
    "\n",
    "# 웹페이지의 HTML 파싱\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 'sa_text_title' 클래스를 가진 요소들 찾기\n",
    "topten_titles = soup.find_all(class_='title')\n",
    "\n",
    "# 추출할 텍스트가 있는 최대 인덱스 설정\n",
    "max_index = 11\n",
    "\n",
    "# 찾은 요소들의 텍스트 추출 및 출력\n",
    "for index, title in enumerate(topten_titles):\n",
    "    if index < max_index:\n",
    "        title_text = title.find('span').text if title.find('span') else title.text\n",
    "        print(title_text.strip())\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
